#!/bin/bash


#######################################
# Login to Azure using the specified tenant if not already logged in.
# Arguments:
#   ID of a tenant to login to.
# Returns:
#   0 If already logged in or login is successful.
#######################################
login_azure() {
  local aad_tenant="$1"

  # Check if already logged in by trying to get an access token with the specified tenant.
  2>/dev/null az account get-access-token --tenant "${aad_tenant}" --output none
  if [[ $? -ne 0 ]] ; then
    echo "Login required to authenticate with Azure."
    echo "Attempting to login to Tenant: ${aad_tenant}"
    az login --output none --tenant "${aad_tenant}"
    if [[ $? -ne 0 ]]; then
      err "Failed to authenticate with Azure"
    fi
  fi
  return 0
}

#######################################
# Removes local state on the filesystem.
# Returns:
#   0 If no errors trying to clean local state.
#######################################
clean_local_state() {
  echo "Cleaning Terraform state."
    
    # Remove local Terraform state.
    rm -rf ".terraform"
    rm .terraform.lock.hcl
    rm out.plan
    return 0

    # TODO, remove /home/$user/.kube/kubeconfig?
}

#######################################
# Removes local state on the filesystem.
# Returns:
#   0 If no errors trying to print versions of prerequisites.
#######################################
print_prereq_vers() {
  # Report terraform version
  terraform -v

  # Report Azure CLI verison
  az --version
}

#######################################
# Create a Resource Group in Azure.
# Arguments:
#   Name for the Resource Group
#   Azure location to create the Resource Group.
# Returns:
#   0 If Resource Group is created.
#######################################
create_resource_group() {
  local resource_group_name="$1"
  local location="$2"

  echo "Checking if resource group ${RESOURCE_GROUP_NAME} exists."
  
  # When a resource group doesn't exist, the `az group exists` command returns anauthorization error.
  local rg_exists
  rg_exists=$(az group exists -n "${RESOURCE_GROUP_NAME}")
  
  if [[ $? -ne 0 ]]; then
    err "Failed to check for existence of resource group ${RESOURCE_GROUP_NAME}. Probably a permissions issue."
    return 1
  fi

  if [[ ${rg_exists} == "true" ]]; then
    echo "Resource group ${RESOURCE_GROUP_NAME} already exists."
    return 1
  else
    echo "Resource group ${RESOURCE_GROUP_NAME} does not exist."
    echo "Creating resource group ${RESOURCE_GROUP_NAME}"
    1>/dev/null az group create --name "${RESOURCE_GROUP_NAME}" --location "${LOCATION}"
    if [[ $? -ne 0 ]]; then
      err "Failed to create resource group ${RESOURCE_GROUP_NAME}"
      return 1
    else
      return 0
    fi
  fi
}

#######################################
# Create a Storage Account in Azure.
# Arguments:
#   Name for the Storage Account
#   Name of the Resource Group
#   Azure location to create the Resource Group.
# Returns:
#   0 If Storage Account is created.
#######################################
create_storage_account() {
  local storage_account_name="$1"
  local resource_group_name="$2"
  local location="$3"
  # Uses jq to parse the json output and grab the "reason" field. -r for raw so there aren't quotes in the string.
  echo "Checking if storage account ${storage_account_name} exists."
  local sa_reason
  sa_reason=$(az storage account check-name -n "${storage_account_name}" | jq -r .reason)
  # TODO This is probably checking the exit code of jq
  # TODO, storage account names need to be globally unique, should add a random string here.
  if [[ $? -ne 0 ]]; then
    err "Failed to check for existence of storage account ${storage_account_name}. Probably a permissions issue."
  fi
  if [[ ${sa_reason} == "AlreadyExists" ]]; then
    echo "Storage account ${storage_account_name} exists."
  else
    echo "Storage account ${storage_account_name} does not exist. Creating it."
    1>/dev/null az storage account create --name "${storage_account_name}" --resource-group "${resource_group_name}" --location "${location}"
    if [[ $? -ne 0 ]]; then
      err "Failed to create storage group ${storage_account_name}"
    fi
  fi
}

#######################################
# Create a Storage Container in Azure.
# Arguments:
#   Name for the Storage Container
#   Name of the Storage Account
# Returns:
#   0 If the Storage Container is created.
#######################################
create_storage_container() {
  local container_name="$1"
  local storage_account_name="$2"
  # User should have "Storage Blob Data Contributor" role.
  # Uses jq to parse the json output and grab the "exists" field.
  container_exists=$(az storage container exists -n "${container_name}" --account-name "${storage_account_name}" --auth-mode login | jq .exists)
  # TODO This is probably checking the exit code of jq
  if [[ $? -ne 0 ]]; then
    err "Failed to check for existence of container ${container_name} in storage account ${storage_account_name}. Probably a permissions issue."
  fi
  if [[ ${container_exists} == "false" ]]; then
      echo "Creating container ${container_name}"
      1>/dev/null az storage container create -n "${container_name}" --account-name "${storage_account_name}" --auth-mode login
      # Wait for storage container to create, TODO consider polling.
      sleep 5
  else
      echo "Container ${container_name} exists."
  fi
}

#######################################
# Write config.mk in the repo root.
# Arguments:
#   Name of the deployment
#   Location of the deployment
# Returns:
#   0 If the config file is created.
#######################################
write_config_mk() {
  local deployment_name="$1"
  local location="$2"

  local cfg="../../config.mk"

  if [ -f ../../config.mk ]; then
    # TODO, warn if config.mk.bak already exists
    mv ${cfg} ../../config.mk.bak
  fi

  # Write out new "config.mk".
  cat << EOF > ${cfg}
PROJECT := ${deployment_name}-rg
REGION := ${location}
ZONE := ${location}
DOCKER_PREFIX := ${deployment_name}acr.azurecr.io
DOCKER_ROOT_IMAGE := \$(DOCKER_PREFIX)/ubuntu:18.04
DOMAIN := ${deployment_name}.azurewebsites.net
INTERNAL_IP := INTERNAL_IP_PLACEHOLDER
IP := IP_PLACEHOLDER
KUBERNETES_SERVER_URL := K8S_SERVER_URL_PLACEHOLDER
ifeq (\$(NAMESPACE),default)
SCOPE = deploy
DEPLOY = true
else
SCOPE = dev
DEPLOY = false
endif
EOF
}

main() {
  # TODO handle failed/partial out of sync deployments, maybe a --destroy command (consistent with the terraform vernacular).
  # If pre-existing azure resources exist that are out of sync with the tf state, then terraform will throw an error stating that 
  # they need to be imported. At the least, we might want to validate that the resources we intend to create can be created before
  # kicking off terraform.

  # Process options.
  while getopts "${GETOPTS_STR}" option; do
    case "${option}" in
      c) should_clean="true";;
      v) is_verbose="true";;
    esac
  done

  # Check if we are running the clean command.
  # To remove all state, remove Terraform container on the cloud. E.g.,
  # az storage container delete -n "${TERAFORM_CONTAINER}" --account-name "${STORAGE_ACCOUNT}" --subscription "${AZURE_SUBSCRIPTION}" --auth-mode login
  if [[ -n ${should_clean} ]]; then
    # Clean and exit.
    clean_local_state
    exit 0
  fi

  # If verbose option, print prereq versions.
  if [[ -n ${is_verbose} ]]; then
    print_prereq_vers
  fi

  # Load variables we need from a .env file if specified. Sourcing it as a script.
  if [ -f .env ]; then
      echo "Found .env file. Sourcing it."
    source ".env"
  else
    echo "No .env found, assuming environment variables are set already."
  fi

  # TODO(saponas) Report expected env vars that are not defined.

  # Login to Azure using the specified tenant if not already logged in.
  # Note, terraform recomments authenticating to az cli manually when running terraform locally,
  # see: https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/guides/managed_service_identity
  login_azure "${AAD_TENANT}"

  # Set the subscription so future commands don't need to specifiy it.
  az account set --subscription "${AZURE_SUBSCRIPTION}"

  # Create resource group if it doesn't exist.
  create_resource_group "${RESOURCE_GROUP_NAME}" "${LOCATION}"

  # Create storage account if it doesn't exist.
  create_storage_account "${STORAGE_ACCOUNT}" "${RESOURCE_GROUP_NAME}" "${LOCATION}"

  # Create container to store teraform information if it doesn't exist.
  create_storage_container "${TERRAFORM_CONTAINER}" "${STORAGE_ACCOUNT}"

  # Get an access key to the storage account.
  # Use jq to grabe the "value" field of the first key. "-r" option gives raw output without quotes.
  local sa_access_key=$(az storage account keys list --resource-group "${RESOURCE_GROUP_NAME}" --account-name "${STORAGE_ACCOUNT}" --subscription "${AZURE_SUBSCRIPTION}" | jq -r .[0].value)
  
  # TODO, might need a check to verify the storage account and container are up and running at this point, script has failed once when needing to create the container, with a ContainerNotFound error message.
  
  # Initialize Terraform with a blob container to store state
  terraform init -backend-config="storage_account_name=${STORAGE_ACCOUNT}" -backend-config="container_name=${TERRAFORM_CONTAINER}" -backend-config="access_key=${sa_access_key}" -backend-config="key=codelab.microsoft.tfstate"

  # TODO, consider using a .tfvars file. Can't directly replace .env because it doesn't support deriving one variable from another, which .env currently does.
  # might be about to write out the tfvars file programmatically here and then use that instead of all the -var args in terraform init/plan.

  # Import a newly created resource group into the configuration because we don't have perms to have Terraform be the creator of the resource group.
  # Only do this if the resource group isn't already there or if the state file doesn't exist. 
  if [ ! -f .terraform/terraform.tfstate ] || ! ( terraform state list | grep -q "azurerm_resource_group.rg" ) ; then
    terraform import  -var deployment_name="${DEPLOYMENT_NAME}" \
                      -var resource_group_name="${RESOURCE_GROUP_NAME}" \
                      -var location="${LOCATION}" \
                      -var ssh_public_key="${SSH_PUBLIC_KEY}" \
                      -var k8s_cluster_name="${K8S_CLUSTER_NAME}" \
                      "azurerm_resource_group.rg" "/subscriptions/${AZURE_SUBSCRIPTION}/resourceGroups/${RESOURCE_GROUP_NAME}"
  fi

  terraform plan -var deployment_name="${DEPLOYMENT_NAME}" -var location="${LOCATION}" -out out.plan

  # Conditionally halt execution if plan failed.
  if [[ ! -f out.plan ]]; then
    err "Terraform plan failed. Halting execution."
  fi

  # Apply the Terraform configuation.
  terraform apply out.plan

  # Connect kubectl to newly created k8s cluster.
  az aks get-credentials -g "${RESOURCE_GROUP_NAME}" -n "${DEPLOYMENT_NAME}vdc"

  # Using the secret stored in vdc during terraform deployment, update config.mk
  # TODO, this should be automated before running script end to end
  kubectl -n default get secret global-config -o json | jq '.data | map_values(@base64d)'

  # Example contents of config.mk on a deployment named mwtftest

  # PROJECT := mwtftest-rg
  # REGION := westus2
  # ZONE := westus2
  # DOCKER_PREFIX := mwtftestacr.azurecr.io
  # DOCKER_ROOT_IMAGE := $(DOCKER_PREFIX)/ubuntu:18.04
  # DOMAIN := mwtftest.azurewebsites.net
  # INTERNAL_IP := 20.190.44.219
  # IP := 52.151.53.179
  # KUBERNETES_SERVER_URL := https://mwtftestvdc-d70e2049.hcp.westus2.azmk8s.io
  # ifeq ($(NAMESPACE),default)
  # SCOPE = deploy
  # DEPLOY = true
  # else
  # SCOPE = dev
  # DEPLOY = false
  # endif

  # Log in to the ACR.
  az acr login -n "${DEPLOYMENT_NAME}acr"

  # Import third-party images into the ACR.
  ./import_images "${DEPLOYMENT_NAME}acr"

}

not_implemented() {
  # Generate TLS certs and apply to the cluster
  openssl req -x509 -newkey rsa:4096 -keyout hail-root-key.pem -out hail-root-cert.pem -days 365 -subj '/CN=localhost' -nodes -sha256
  kubectl create secret generic \
          -n default ssl-config-hail-root \
          --from-file=hail-root-key.pem \
          --from-file=hail-root-cert.pem \
          --save-config \
          --dry-run=client \
          -o yaml \
      | kubectl apply -f -

  # Apply ci/bootstrap.yaml.
  kubectl -n default apply -f ../../ci/bootstrap.yaml

  # Build the CI utils image.
  # TODO: This can fail if permissions on the repo files are wrong, they need to be 644, since we're not working from a VM where we're
  # cloning the hail repo and can set umask before cloning, we will need to provide instructions as to how to modify permissions on
  # the repo after cloning.
  # As a temporary hack can `chmod g-w -R $REPO_ROOT'
  # TODO: this seems to fail on first execution in a clean repo (N=2), but then succeeds on second execution. Investigate.
  #   had to reorder some steps in underlying make files, possibly a race condition?
  make -C ../../ci push-ci-utils
  
  # Deploy the bootstrap gateway
  make -C ../../bootstrap-gateway deploy

  # Create Let's Encrypt certs
  # TODO, the Dockerfile here pulls kubectl from google storage, consider moving.
  # TODO, manually changed $ROOT/letsencrypt/letsencrypt.sh to not have container running certbot send agree-tos cseed@.
  make -C ../../letsencrypt run
}



# Run main.
main "$@"