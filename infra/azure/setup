#!/bin/bash
# Setup a Hail batch deployment on Azure.
# Usage ./setup [-c]
#   -c: Clean up local and remote Terraform state.
#
# Script should follow style https://google.github.io/styleguide/shellguide.html
#
# If you are using an Azure subcription with default settings and the default user,
# the only change you should have to make before running this script (besides defining the
# environment variables below) is adding the "Storage Blob Data Contributor" role to your
# user at the subcription level. Of course you could also do this at the resource group
# level instead after creating the resource group.
#
# TODO Add notes about creating the resource group or other resources beforing running
# the script if you would prefer to create them outside of this script.
#
# Environment variables that need to be set or provided with `-f .env`. See also `example.env`.
#   - AAD_TENANT
#   - AZURE_SUBSCRIPTION
#   - DEPLOYMENT_NAME
#   - RESOURCE_GROUP_NAME
#   - LOCATION
#   - STORAGE_ACCOUNT
#   - TERRAFORM_CONTAINER
#   - SSH_PUBLIC_KEY

#############
# Constants #
#############

# Command line options.
readonly GETOPTS_STR="cv"

#############
# Functions #
#############

err() {
  echo -e "${ANSI_RED}ERROR: $*${ANSI_RESET}" >&2
  exit 1
}

#######################################
# Login to Azure using the specified tenant if not already logged in.
# Arguments:
#   ID of a tenant to login to.
# Returns:
#   0 If already logged in or login is successful.
#######################################
login_azure() {
  local aad_tenant="$1"

  # Check if already logged in by trying to get an access token with the specified tenant.
  2>/dev/null az account get-access-token --tenant "${aad_tenant}" --output none
  if [[ $? -ne 0 ]] ; then
    echo "Login required to authenticate with Azure."
    echo "Attempting to login to Tenant: ${aad_tenant}"
    az login --output none --tenant "${aad_tenant}"
    if [[ $? -ne 0 ]]; then
      err "Failed to authenticate with Azure"
    fi
  fi
  return 0
}

#######################################
# Removes local state on the filesystem.
# Returns:
#   0 If no errors trying to clean local state.
#######################################
clean_local_state() {
  echo "Cleaning Terraform state."
    
    # Remove local Terraform state.
    rm -rf ".terraform"
    rm .terraform.lock.hcl
    rm out.plan
    return 0
}

#######################################
# Removes local state on the filesystem.
# Returns:
#   0 If no errors trying to print versions of prerequisites.
#######################################
print_prereq_vers() {
  # Report terraform version
  terraform -v

  # Report Azure CLI verison
  az --version
}

#######################################
# Create a Resource Group in Azure.
# Arguments:
#   Name for the Resource Group
#   Azure location to create the Resource Group.
# Returns:
#   0 If Resource Group is created.
#######################################
create_resource_group() {
  local resource_group_name="$1"
  local location="$2"

  echo "Checking if resource group ${RESOURCE_GROUP_NAME} exists."
  
  # When a resource group doesn't exist, the `az group exists` command returns anauthorization error.
  local rg_exists
  rg_exists=$(az group exists -n "${RESOURCE_GROUP_NAME}")
  
  if [[ $? -ne 0 ]]; then
    err "Failed to check for existence of resource group ${RESOURCE_GROUP_NAME}. Probably a permissions issue."
    return 1
  fi

  if [[ ${rg_exists} == "true" ]]; then
    echo "Resource group ${RESOURCE_GROUP_NAME} already exists."
    return 1
  else
    echo "Resource group ${RESOURCE_GROUP_NAME} does not exist."
    echo "Creating resource group ${RESOURCE_GROUP_NAME}"
    1>/dev/null az group create --name "${RESOURCE_GROUP_NAME}" --location "${LOCATION}"
    if [[ $? -ne 0 ]]; then
      err "Failed to create resource group ${RESOURCE_GROUP_NAME}"
      return 1
    else
      return 0
    fi
  fi
}

#######################################
# Create a Storage Account in Azure.
# Arguments:
#   Name for the Storage Account
#   Name of the Resource Group
#   Azure location to create the Resource Group.
# Returns:
#   0 If Storage Account is created.
#######################################
create_storage_account() {
  local storage_account_name="$1"
  local resource_group_name="$2"
  local location="$3"
  # Uses jq to parse the json output and grab the "reason" field. -r for raw so there aren't quotes in the string.
  echo "Checking if storage account ${storage_account_name} exists."
  local sa_reason
  sa_reason=$(az storage account check-name -n "${storage_account_name}" | jq -r .reason)
  # TODO This is probably checking the exit code of jq
  if [[ $? -ne 0 ]]; then
    err "Failed to check for existence of storage account ${storage_account_name}. Probably a permissions issue."
  fi
  if [[ ${sa_reason} == "AlreadyExists" ]]; then
    echo "Storage account ${storage_account_name} exists."
  else
    echo "Storage account ${storage_account_name} does not exist. Creating it."
    1>/dev/null az storage account create --name "${storage_account_name}" --resource-group "${resource_group_name}" --location "${location}"
    if [[ $? -ne 0 ]]; then
      err "Failed to create storage group ${storage_account_name}"
    fi
  fi
}

#######################################
# Create a Storage Container in Azure.
# Arguments:
#   Name for the Storage Container
#   Name of the Storage Account
# Returns:
#   0 If the Storage Container is created.
#######################################
create_storage_container() {
  local container_name="$1"
  local storage_account_name="$2"
  # User should have "Storage Blob Data Contributor" role.
  # Uses jq to parse the json output and grab the "exists" field.
  container_exists=$(az storage container exists -n "${container_name}" --account-name "${storage_account_name}" --auth-mode login | jq .exists)
  # TODO This is probably checking the exit code of jq
  if [[ $? -ne 0 ]]; then
    err "Failed to check for existence of container ${container_name} in storage account ${storage_account_name}. Probably a permissions issue."
  fi
  if [[ ${container_exists} == "false" ]]; then
      echo "Creating container ${container_name}"
      1>/dev/null az storage container create -n "${container_name}" --account-name "${storage_account_name}" --auth-mode login
  else
      echo "Container ${container_name} exists."
  fi
}

#######################################
# Write config.mk in the repo root.
# Arguments:
#   Name of the deployment
#   Location of the deployment
# Returns:
#   0 If the config file is created.
#######################################
write_config_mk() {
  local deployment_name="$1"
  local location="$2"

  local cfg="../../config.mk"

  if [ -f ../../config.mk ]; then
    # TODO, warn if config.mk.bak already exists
    mv ${cfg} ../../config.mk.bak
  fi

  # Write out new "config.mk".
  cat << EOF > ${cfg}
PROJECT := ${deployment_name}-rg
REGION := ${location}
ZONE := ${location}
DOCKER_PREFIX := ${deployment_name}acr.azurecr.io
DOCKER_ROOT_IMAGE := \$(DOCKER_PREFIX)/ubuntu:18.04
DOMAIN := TODO
INTERNAL_IP := TODO
IP := TODO
KUBERNETES_SERVER_URL := TODO
ifeq (\$(NAMESPACE),default)
SCOPE = deploy
DEPLOY = true
else
SCOPE = dev
DEPLOY = false
endif
EOF
}

main() {
  # TODO handle failed/partial out of sync deployments, maybe a --destroy command (consistent with the terraform vernacular).
  # If pre-existing azure resources exist that are out of sync with the tf state, then terraform will throw an error stating that 
  # they need to be imported. At the least, we might want to validate that the resources we intend to create can be created before
  # kicking off terraform.

  # Process options.
  while getopts "${GETOPTS_STR}" option; do
    case "${option}" in
      c) should_clean="true";;
      v) is_verbose="true";;
    esac
  done

  # Check if we are running the clean command.
  # To remove all state, remove Terraform container on the cloud. E.g.,
  # az storage container delete -n "${TERAFORM_CONTAINER}" --account-name "${STORAGE_ACCOUNT}" --subscription "${AZURE_SUBSCRIPTION}" --auth-mode login
  if [[ -n ${should_clean} ]]; then
    # Clean and exit.
    clean_local_state
    exit 0
  fi

  # If verbose option, print prereq versions.
  if [[ -n ${is_verbose} ]]; then
    print_prereq_vers
  fi

  # Load variables we need from a .env file if specified. Sourcing it as a script.
  if [ -f .env ]; then
      echo "Found .env file. Sourcing it."
    source ".env"
  else
    echo "No .env found, assuming environment variables are set already."
  fi

  # TODO(saponas) Report expected env vars that are not defined.

  # Login to Azure using the specified tenant if not already logged in.
  login_azure "${AAD_TENANT}"

  # Set the subscription so future commands don't need to specifiy it.
  az account set --subscription "${AZURE_SUBSCRIPTION}"

  # Create resource group if it doesn't exist.
  create_resource_group "${RESOURCE_GROUP_NAME}" "${LOCATION}"

  # Create storage account if it doesn't exist.
  create_storage_account "${STORAGE_ACCOUNT}" "${RESOURCE_GROUP_NAME}" "${LOCATION}"

  # Create container to store teraform information if it doesn't exist.
  create_storage_container "${TERRAFORM_CONTAINER}" "${STORAGE_ACCOUNT}"

  # Get an access key to the storage account.
  # Use jq to grabe the "value" field of the first key. "-r" option gives raw output without quotes.
  local sa_access_key=$(az storage account keys list --resource-group "${RESOURCE_GROUP_NAME}" --account-name "${STORAGE_ACCOUNT}" --subscription "${AZURE_SUBSCRIPTION}" | jq -r .[0].value)

  #### Create AKS cluster with Terraform ####

  # TODO, might need a check to verify the storage account and container are up and running at this point, script has failed once when needing to create the container, with a ContainerNotFound error message.
  
  # Initialize Terraform with a blob container to store state
  terraform init -backend-config="storage_account_name=${STORAGE_ACCOUNT}" -backend-config="container_name=${TERRAFORM_CONTAINER}" -backend-config="access_key=${sa_access_key}" -backend-config="key=codelab.microsoft.tfstate"
  
  # TODO, consider using a .tfvars file. Can't directly replace .env because it doesn't support deriving one variable from another, which .env currently does.
  # might be about to write out the tfvars file programmatically here and then use that instead of all the -var args in terraform init/plan.

  # Import a newly created resource group into the configuration because we don't have perms to have Terraform be the creator of the resource group.
  # Only do this if the resource group isn't already there or if the state file doesn't exist. 
  if [ ! -f .terraform/terraform.tfstate ] || ! ( terraform state list | grep -q "azurerm_resource_group.rg" ) ; then
    terraform import  -var deployment_name="${DEPLOYMENT_NAME}" \
                      -var resource_group_name="${RESOURCE_GROUP_NAME}" \
                      -var location="${LOCATION}" \
                      -var ssh_public_key="${SSH_PUBLIC_KEY}" \
                      -var k8s_cluster_name="${K8S_CLUSTER_NAME}" \
                      "azurerm_resource_group.rg" "/subscriptions/${AZURE_SUBSCRIPTION}/resourceGroups/${RESOURCE_GROUP_NAME}"
  fi

  # Have Terraform create a plan and save it to file.
  terraform plan  -out out.plan \
                  -var deployment_name="${DEPLOYMENT_NAME}" \
                  -var resource_group_name="${RESOURCE_GROUP_NAME}" \
                  -var location="${LOCATION}" \
                  -var ssh_public_key="${SSH_PUBLIC_KEY}" \
                  -var k8s_cluster_name="${K8S_CLUSTER_NAME}"

  # Conditionally halt execution if plan failed.
  if [[ ! -f out.plan ]]; then
    err "Terraform plan failed. Halting execution."
  fi

  # Apply the Terraform configuation.
  terraform apply out.plan

  # Connect kubectl to newly created k8s cluster.
  # TODO, kubernetes cluster name should be deployment specific
  az aks get-credentials --resource-group "${RESOURCE_GROUP_NAME}" --name "${K8S_CLUSTER_NAME}"
  
  # Get the name for the default k8s config secret.
  # k8s_secret_name=$(kubectl -n default get secret -o json | jq -r '.items[0].metadata.name')
  # kubectl -n default get secret ${k8s_secret_name} -o json | jq '.data | map_values(@base64d)'
  # TODO update $HAIL/config.mk with the above information.

  # Write config.mk with relevant deployment info.
  write_config_mk ${DEPLOYMENT_NAME} ${LOCATION}

  # Log in to the ACR.
  az acr login -n "${DEPLOYMENT_NAME}acr"

  # Copy third-party docker images, this will take a while as configured, since the images will be pulled from docker.io locally
  # then pushed to the new ACR.
  cwd=$(pwd)
  cd ../../docker/third-party/
  make copy
  cd $cwd

  # Generate TLS certs.
  openssl req -x509 -newkey rsa:4096 -keyout server-key.pem -out server-cert.pem -days 365 -subj '/CN=localhost' -nodes -sha256

  # Apply ci/bootstrap.yaml.
  kubectl -n default apply -f ../../ci/bootstrap.yaml

  # Build the CI utils image.
  cwd=$(pwd)
  cd ../../ci/
  make push-ci-utils
}

# Run main.
main "$@"
